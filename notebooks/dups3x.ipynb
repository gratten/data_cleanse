{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\WDG1DCR\\\\Desktop\\\\my_projects\\\\data_analysis\\\\data_cleanse')\n",
    "\n",
    "import pandas as pd\n",
    "from prep import filter\n",
    "from prep import sort\n",
    "from plot import bar\n",
    "from utility import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'filelist_7_15'\n",
    "df_og = pd.read_csv('datasets/' + fileName + '.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter.sld(df_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df[df.duplicated(['name_low'], keep=False)]\n",
    "dups = dups.sort_values(['name_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this bit organizes the data into filename, path1, path2, path3, etc columns\n",
    "# the intent is to eventually create a function that receives iput of column qty\n",
    "# and outputs corresponding data fram\n",
    "# right now, it's set up for 3 path columns + 1 filename column\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "names = []\n",
    "paths = []\n",
    "\n",
    "for i in range(0, len(dups)):\n",
    "    names.append(dups['Name'].iloc[i])\n",
    "    paths.append(dups['path'].iloc[i])\n",
    "\n",
    "s = zip(names, paths)\n",
    "d = defaultdict(list)\n",
    "for k, v in s:\n",
    "    d[k].append(v)\n",
    "\n",
    "# restructure into new df (pairs) containing only pairs of duplicate paths\n",
    "df_names = []\n",
    "df_path1 = []\n",
    "df_path2 = []\n",
    "df_path3 = []\n",
    "for k, v in d.items():\n",
    "    if len(v) == 3:\n",
    "        df_names.append(k)\n",
    "        df_path1.append(v[0])\n",
    "        df_path2.append(v[1])\n",
    "        df_path3.append(v[2])\n",
    "        \n",
    "path_data = {'name':df_names, 'path1':df_path1, 'path2':df_path2, 'path3':df_path3}\n",
    "paths = pd.DataFrame(data=path_data)\n",
    "paths = paths.sort_values(['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_0 = paths.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_collection0 = {}\n",
    "output_collection1 = {}\n",
    "output_collection2 = {}\n",
    "\n",
    "dropped_col_list0 = []\n",
    "dropped_col_list1 = []\n",
    "dropped_col_list2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is also intended to eventually be path qty independent\n",
    "# aka wil work for x2 paths, x3 paths, x4 paths, etc\n",
    "# right now it's set up for x3 paths only\n",
    "\n",
    "def generate(df_target, dropped_col):\n",
    "       \n",
    "    output_collection1, dropped_col_list1 = sort.chunk2(df_target)\n",
    "\n",
    "    temp_inc0 = 0\n",
    "\n",
    "    rebuild_collection2 = {}\n",
    "    for key in output_collection1.keys():\n",
    "        output_collection2, dropped_col_list2 = sort.chunk2(output_collection1[key])\n",
    "\n",
    "        df_rebuild2 = sort.rebuild(output_collection2, dropped_col_list2, 'path3')\n",
    "        rebuild_collection2[key] = df_rebuild2\n",
    "\n",
    "    #     temp_inc0 += 1\n",
    "    #     if temp_inc0 >= 2:\n",
    "    #         break\n",
    "\n",
    "    df_rebuild1 = sort.rebuild(rebuild_collection2, dropped_col_list1, 'path2')\n",
    "    df_rebuild1.insert(1, 'path1', dropped_col)\n",
    "    columns_titles = ['name', 'path1', 'path2', 'path3']\n",
    "    df_out=df_rebuild1.reindex(columns=columns_titles)\n",
    "\n",
    "    sheetName = dropped_col.split('\\\\', -1)\n",
    "    sheetName = sheetName[len(sheetName)-1]\n",
    "    sheetName = sheetName[:25]\n",
    "\n",
    "    return df_out, sheetName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_collection0, dropped_col_list0 = sort.chunk2(df_input_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose how many directories to analyze\n",
    "num = 20\n",
    "\n",
    "df_out_collection = {}\n",
    "sheetName_list = []\n",
    "\n",
    "for i in range(num):\n",
    "    \n",
    "    dict_key_list = list(output_collection0.keys())\n",
    "    dict_key = dict_key_list[i]\n",
    "    \n",
    "    df_target = output_collection0[dict_key].copy()\n",
    "    dropped_col = dropped_col_list0[i]\n",
    "\n",
    "    df_out, sheetName = generate(df_target, dropped_col)\n",
    "    \n",
    "    df_out_collection[i] = df_out\n",
    "    sheetName_list.append(sheetName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"output_files\\\\output.xlsx\"\n",
    "\n",
    "df_out.to_excel(fname,\n",
    "             sheet_name=sheetName)\n",
    "\n",
    "with pd.ExcelWriter(fname) as writer: \n",
    "    for i in range(num):\n",
    "        df_out_collection[i].to_excel(writer, sheet_name=sheetName_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
